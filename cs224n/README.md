# CS224N: Deep Learning with Natural Language Processing
My solutions to Stanford's public course [CS224N: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/index.html#schedule), taught by Christopher Manning (Winter 2021).
Lectures are freely available on [YouTube](https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ). 

# About Me
I am a 3rd year at the University of Texas at Austin (hook'em!) studying Electrical and Computer Engineering and Math. I've decided to complete this course (as well as other public courses [EECS498: Deep Learning for Computer Vision](https://github.com/bensmidt/EECS-498-DL-Computer-Vision) and [CS229: Machine Learning](https://github.com/bensmidt/CS229-ML-Autumn-2018)) in an effort to learn about Machine Learning and Deep Learning from a mathematical foundation. 

You can find out more about me at my [LinkedIn](https://www.linkedin.com/in/benjamin-smidt/). If you have any questions about my solutions, learning machine learning, or just want connect, feel free to follow me and reach out on LinkedIn or email me at benjamin.smidt@utexas.edu. I can be a little slow to respond depending my current responsiblities but I can assure you I will respond! I hope you enjoy this course as much as I have and that my solutions are helpful. 

Last thing, big thank you to Stanford for making these lectures and course material publically available! They are immensely helpful and provide amazing opportunity to learn from many of the best minds in computer science (and other fields). They've been vital in my machine learning journey. 

# Assignments
There are a total of 5 assignments of varying length. For the first assignment, instructions are embedded in the provided notebook. However, all other assignments (2-5) have an instruction pdf to go along with some provided boilerplate files and code. Additionally, each assignment has a corresponding pdf (written by myself using LaTex) explaining my thought process, showing my work, and giving general tips. There are a total of 5 assignments, each of which are a directory (1st Assignment = "A1", 2nd = "A2", etc.). All coding assignments are programmed in Python using PyTorch and NumPy. Assignments 4 and 5 use Virtual Machines with Azure, which I don't have access to. I just used Google Colab instead. 

If you want to see the assignments without my code (eg. you want to do it yourself!), they can be found on the [course website](https://web.stanford.edu/class/cs224n/index.html#schedule)

## Assignment 1: Exploring Word Vectors
  - [exploring_word_vectors.ipynb](https://github.com/bensmidt/CS224N-Deep-Learning-NLP/blob/main/A1/exploring_word_vectors.ipynb)
  - [PDF Work/Explanations](https://github.com/bensmidt/CS224N-DL-NLP/blob/main/A1/A1-ExploringWordVectors.pdf)

## Assignment 2: Word2Vec
  - [Instructions](https://github.com/bensmidt/CS224N-Deep-Learning-NLP/blob/main/A2/A2-Instructions.pdf)
  - [word2vec.py](https://github.com/bensmidt/CS224N-Deep-Learning-NLP/blob/main/A2/word2vec.py)
  - [sgd.py](https://github.com/bensmidt/CS224N-Deep-Learning-NLP/blob/main/A2/sgd.py)
  - [PDF Work/Explanations](https://github.com/bensmidt/CS224N-DL-NLP/blob/main/A2/A2-Latex/A2-Word2Vec.pdf)
  - [word_vectors.png](https://github.com/bensmidt/CS224N-DL-NLP/blob/main/A2/word_vectors.png)

## Assignment 3: Dependency Parsing with Neural Networks
  - [Instructions](https://github.com/bensmidt/CS224N-DL-Natural-Language-Processing/blob/main/A3/a3-instructions.pdf)
  - [parser_transitions.py](https://github.com/bensmidt/CS224N-DL-Natural-Language-Processing/blob/main/A3/parser_transitions.py)
  - [parser_model.py](https://github.com/bensmidt/CS224N-DL-Natural-Language-Processing/blob/main/A3/parser_model.py)
  - [PDF Work/Explanations](https://github.com/bensmidt/CS224N-DL-Natural-Language-Processing/blob/main/A3/a3-latex/A3-NNs_Dependency_Parsing.pdf)

## Assignment 4: Machine Translation with RNNs
  - [Instructions](https://github.com/bensmidt/CS224N-DL-Natural-Language-Processing/blob/main/A4/A4-Instructions.pdf)
  - [model_embeddings.py](https://github.com/bensmidt/CS224N-DL-Natural-Language-Processing/blob/main/A4/model_embeddings.py)
  - [nmt_model.py](https://github.com/bensmidt/CS224N-DL-Natural-Language-Processing/blob/main/A4/nmt_model.py)
  - [PDF Work/Explanations](https://github.com/bensmidt/CS224N-DL-Natural-Language-Processing/blob/main/A4/A4-Latex/A4-NMT_RNN.pdf)

## Assignment 5: Self-Attention, Transformers, and Pretraining
- [Instructions](https://github.com/bensmidt/CS224N-DL-Natural-Language-Processing/blob/main/A5/A5-Instructions.pdf)
